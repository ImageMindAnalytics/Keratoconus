{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('/work/jprieto/source/Keratoconus/src/py')\n",
    "import dataset\n",
    "import argparse\n",
    "import nets \n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Train a model on the keratoconus dataset')\n",
    "\n",
    "parser = dataset.ImgSegDataModule.add_data_specific_args(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "def get_argparse_dict(parser):\n",
    "    # Get the default arguments from the parser\n",
    "    default = {}\n",
    "    for action in parser._actions:\n",
    "        if action.dest != \"help\":\n",
    "            default[action.dest] = action.default\n",
    "    return default\n",
    "\n",
    "args = get_argparse_dict(parser)\n",
    "\n",
    "args = Namespace(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# args_d = vars(args)\n",
    "\n",
    "# args_d['csv_train'] = '/CMF/data/lumargot/Keratoconus/preprocess/kc_filtered_trachoma_seg_train_train.csv'\n",
    "# args_d['csv_valid'] = '/CMF/data/lumargot/Keratoconus/preprocess/kc_filtered_trachoma_seg_train_test.csv'\n",
    "# args_d['csv_test'] = '/CMF/data/lumargot/Keratoconus/preprocess/kc_filtered_trachoma_seg_test.csv'\n",
    "# args_d['mount_point'] = '/CMF/data/lumargot/Keratoconus/preprocess'\n",
    "\n",
    "# dm = dataset.ImgSegDataModule(**args_d)\n",
    "# dm.setup()\n",
    "\n",
    "# train_dl = dm.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv('/CMF/data/lumargot/Keratoconus/csv/keratoconous_files_seg.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.histogram(df, x=\"K1\", nbins=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.histogram(df, x=\"K2\", nbins=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.histogram(df, x=\"Kmean\", nbins=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = dataset.ImgSegDataset(df, mount_point='/CMF/data/lumargot/Keratoconus/preprocess/', img_column='path', seg_column='seg', transform=dataset.EvalTransform(img_key=\"path\", seg_key=\"seg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nets.AutoEncoderKL.load_from_checkpoint('/CMF/data/lumargot/Keratoconus/train_output/autoencoderkl/v0.2/epoch=149-val_loss=0.02.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval().cuda()\n",
    "z_mus = []\n",
    "with torch.no_grad():\n",
    "\n",
    "    for img_d in test_ds:\n",
    "    \n",
    "        img = img_d['path']\n",
    "        \n",
    "        _, z_mu, z_sigma = model(img.unsqueeze(0).cuda())\n",
    "        z_mus.append(z_mu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mus_np = torch.cat(z_mus, dim=0).flatten(1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# df['class'] = pd.cut(df['K1'], bins=4, labels=[0, 1, 2, 3])\n",
    "# px.histogram(df, x=\"class\", nbins=4)\n",
    "\n",
    "# Define the bins and labels\n",
    "bins = [-float('inf'), 40, 47, float('inf')]\n",
    "labels = [0, 1, 2]\n",
    "df['class'] = pd.cut(df['K1'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "px.histogram(df, x=\"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = z_mus_np\n",
    "y = df['class'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Create histogram traces for y_train and y_test\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=y_train,\n",
    "    name='y_train',\n",
    "    marker=dict(color='blue', opacity=0.7)\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=y_test,\n",
    "    name='y_test',\n",
    "    marker=dict(color='orange', opacity=0.7)\n",
    "))\n",
    "\n",
    "# Update layout for stacked histogram\n",
    "fig.update_layout(\n",
    "    barmode='stack',\n",
    "    title='Stacked Histogram of y_train and y_test',\n",
    "    xaxis_title='Values',\n",
    "    yaxis_title='Count',\n",
    "    legend_title='Dataset',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier#create new a knn model\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier()#create a dictionary of all values we want to test for n_neighbors\n",
    "params_knn = {'n_neighbors': np.arange(1, 25)}#use gridsearch to test all values for n_neighbors\n",
    "knn_gs = GridSearchCV(knn, params_knn, cv=5)#fit model to training data\n",
    "knn_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save best model\n",
    "knn_best = knn_gs.best_estimator_#check best n_neigbors value\n",
    "print(knn_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier#create a new random forest classifier\n",
    "rf = RandomForestClassifier()#create a dictionary of all values we want to test for n_estimators\n",
    "params_rf = {'n_estimators': [5, 10, 50, 100, 200, 1000]}#use gridsearch to test all values for n_estimators\n",
    "rf_gs = GridSearchCV(rf, params_rf, cv=5)#fit model to training data\n",
    "rf_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save best model\n",
    "rf_best = rf_gs.best_estimator_#check best n_estimators value\n",
    "print(rf_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression#create a new logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=10000)#fit the model to the training data\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the three models with the test data and print their accuracy scores\n",
    "\n",
    "print('knn: {}'.format(knn_best.score(X_test, y_test)))\n",
    "print('rf: {}'.format(rf_best.score(X_test, y_test)))\n",
    "print('log_reg: {}'.format(log_reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier#create a dictionary of our models\n",
    "estimators=[('knn', knn_best), ('rf', rf_best), ('log_reg', log_reg)]#create our voting classifier, inputting our models\n",
    "ensemble = VotingClassifier(estimators, voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit model to training data\n",
    "ensemble.fit(X_train, y_train)#test our model on the test data\n",
    "ensemble.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "X_pred = ensemble.predict(X_test)\n",
    "\n",
    "# Assuming y_test contains true labels and X_pred contains predicted labels\n",
    "conf_matrix = confusion_matrix(y_test, X_pred, normalize='true')\n",
    "\n",
    "# Create a confusion matrix display\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "X_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Assuming y_test contains true labels and X_pred contains predicted labels\n",
    "conf_matrix = confusion_matrix(y_test, X_pred, normalize='true')\n",
    "\n",
    "# Create a confusion matrix display\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=ensemble.classes_)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(y_test, X_pred)\n",
    "\n",
    "# Print the report\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
